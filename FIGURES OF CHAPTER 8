##############
# CHAPTER 8 #
##############

# Figure 8.1 The illustration of the top 20 most frequent items, distribution of transaction sizes, item frequency (support > 5%), and matrix of the first 100 transactions using the Groceries dataset that is preloaded with the arules package. It contains transactional data for a supermarket.
# Load required libraries
library(arules)
library(arulesViz)

# Load the Groceries dataset
data("Groceries")

# Check the structure of the dataset
summary(Groceries)

# Basic information about the dataset
cat("Number of transactions: ", length(Groceries), "\n")
cat("Number of items: ", length(itemLabels(Groceries)), "\n")

# Inspecting a few transactions
inspect(Groceries[1:5])

# Top items by frequency
itemFrequencyPlot(Groceries, topN = 20, col = "steelblue", 
                  main = "Top 20 Most Frequent Items", 
                  ylab = "Proportion", 
                  xlab = "Items")

# Distribution of transaction sizes
transaction_sizes <- size(Groceries)
hist(transaction_sizes, breaks = 20, col = "lightblue", 
     main = "Distribution of Transaction Sizes", 
     xlab = "Number of Items per Transaction")

# Summary statistics of transaction sizes
summary(transaction_sizes)

# Visualize item frequency (word cloud-like plot)
itemFrequencyPlot(Groceries, support = 0.05, 
                  col = rainbow(10), 
                  main = "Item Frequency (Support > 5%)")

# Association rules (basic example for visualization)
rules <- apriori(Groceries, parameter = list(support = 0.01, confidence = 0.5))
summary(rules)

# Plot the top 10 rules
inspect(sort(rules, by = "lift")[1:10])
plot(rules[1:10], method = "graph", control = list(type = "items"))

# Plot a matrix of items and transactions
image(Groceries[1:100], main = "Matrix of First 100 Transactions", xlab = "Items", ylab = "Transactions")

#Figure 8.2 Decision tree of Groceries dataset for classification tasks.
# Install necessary packages if they are not installed
if (!require(rpart)) install.packages("rpart", dependencies = TRUE)
if (!require(rpart.plot)) install.packages("rpart.plot", dependencies = TRUE)
if (!require(arules)) install.packages("arules", dependencies = TRUE)

# Load libraries
library(rpart)
library(rpart.plot)
library(arules)

# Load the Groceries dataset
data("Groceries")

# Convert the Groceries dataset to a transactions object
groceries_trans <- as(Groceries, "transactions")

# Create a data frame from the transactions data
# Since the decision tree model needs numeric or factor data, 
# we'll use item frequency as the features for the decision tree.
item_freq <- itemFrequency(groceries_trans)
df <- data.frame(item = names(item_freq), freq = item_freq)

# Create a binary target variable for decision tree classification (e.g., if an item appears or not)
df$target <- ifelse(df$freq > 0.02, 1, 0)  # Target: 1 if the item is frequent, 0 otherwise

# Fit a decision tree model using rpart
tree_model <- rpart(target ~ freq, data = df, method = "class")

# Plot the decision tree
rpart.plot(tree_model, main = "Decision Tree for Groceries Dataset")


#Figure 8.3 Scatterplot of Groceries data, Regression: Actual vs Predicted Frequencies.
# Install required packages if not already installed
install.packages("arules")
install.packages("ggplot2")

# Load the libraries
library(arules)
library(ggplot2)

# Load the Groceries dataset
data("Groceries")

# View the first few rows of the dataset
summary(Groceries)

# Convert the Groceries transactions to a data frame
groceries_df <- as(Groceries, "data.frame")

# In a typical grocery dataset, each row represents a transaction.
# To use regression, we need to summarize the data into a suitable format.
# Here, we'll sum up the frequency of each item across all transactions.
groceries_summary <- table(groceries_df$items)

# Convert the table to a data frame
groceries_summary_df <- as.data.frame(groceries_summary)

# Rename the columns for clarity
colnames(groceries_summary_df) <- c("Item", "Frequency")

# Let's assume we want to predict 'Frequency' based on the 'Item' (converted to numeric).
# Since 'Item' is categorical, we'll need to convert it into a factor or numeric form.
groceries_summary_df$Item_numeric <- as.numeric(factor(groceries_summary_df$Item))

# Build a linear regression model: predict Frequency based on Item (numeric representation)
model <- lm(Frequency ~ Item_numeric, data = groceries_summary_df)

# View the model summary
summary(model)

# Create predictions using the model
groceries_summary_df$Predicted_Frequency <- predict(model, newdata = groceries_summary_df)

# Plot the actual vs predicted values
ggplot(groceries_summary_df, aes(x = Frequency, y = Predicted_Frequency)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "",
       x = "Actual Frequency",
       y = "Predicted Frequency") +
  theme_minimal(base_size = 20)

#Figure 8.4 Clustering using K-means and hierarchical clustering (PCA was used to reduce dimensions for better visualization) of Groceries dataset.
# Load necessary libraries
library(arules)
library(ggplot2)
library(cluster)
library(factoextra)

# Load Groceries dataset
data("Groceries")

# Convert the Groceries data into a matrix format for clustering
groceries_matrix <- as(Groceries, "matrix")

# Step 1: Apply K-means Clustering
set.seed(123)  # For reproducibility
kmeans_result <- kmeans(groceries_matrix, centers = 4)  # Assuming 4 clusters

# Step 2: Hierarchical Clustering
dist_matrix <- dist(groceries_matrix)  # Calculate the distance matrix
hclust_result <- hclust(dist_matrix)  # Perform hierarchical clustering

# Step 3: Create ggplot for K-means
# We will reduce dimensions using PCA for better visualization
pca_result <- prcomp(groceries_matrix, scale. = TRUE)
pca_data <- data.frame(pca_result$x)

# Add the K-means cluster results to the PCA data
pca_data$kmeans_cluster <- as.factor(kmeans_result$cluster)

# Plot the K-means clustering result
ggplot(pca_data, aes(x = PC1, y = PC2, color = kmeans_cluster)) +
  geom_point(alpha = 0.7) +
  labs(title = "", x = "Principal Component 1", y = "Principal Component 2") +
  theme_minimal(base_size = 20)

# Step 4: Create ggplot for Hierarchical Clustering
# Cut the hierarchical tree into 4 clusters
hclust_clusters <- cutree(hclust_result, k = 4)

# Add hierarchical clustering result to PCA data
pca_data$hclust_cluster <- as.factor(hclust_clusters)

# Plot the Hierarchical clustering result
ggplot(pca_data, aes(x = PC1, y = PC2, color = hclust_cluster)) +
  geom_point(alpha = 0.7) +
  labs(title = "", x = "Principal Component 1", y = "Principal Component 2") +
  theme_minimal(base_size = 20)

# Additional: Visualizing the Dendrogram for hierarchical clustering
plot(hclust_result, main = "Dendrogram of Groceries Dataset")



#Figure 8.5 The scatterplots, graph visualizations, and rules where the item "whole milk" is on the right-hand side.

# Load necessary libraries
if (!require("arules")) install.packages("arules")
library(arules)

# Load the Groceries dataset
data("Groceries")

# Inspect the dataset
summary(Groceries)
inspect(head(Groceries, 5))  # View first 5 transactions

# Generate association rules
rules <- apriori(Groceries, 
                 parameter = list(supp = 0.01, conf = 0.5, target = "rules"))

# Inspect the rules
total_rules <- length(rules)
cat("Number of rules generated:", total_rules, "\n")

# Show top 10 rules sorted by lift
inspect(head(sort(rules, by = "lift"), 10))

# Visualize the rules (requires arulesViz package)
if (!require("arulesViz")) install.packages("arulesViz")
library(arulesViz)

plot(rules, method = "scatterplot", measure = c("support", "confidence"), shading = "lift")
plot(rules, method = "graph", control = list(type = "items"))

# Filter rules for specific insights
# Example: Rules where the item "whole milk" is in the right-hand side
milk_rules <- subset(rules, rhs %in% "whole milk")
inspect(head(sort(milk_rules, by = "lift"), 10))

# Save the rules to a CSV file
write(rules, file = "association_rules.csv", sep = ",", quote = TRUE, row.names = FALSE)


#Figure 8.6 The rules quality metric and rules with highest support, confidence, and lift for evaluation using the Groce​​ries dataset.
# Load necessary libraries
if (!require("arules")) install.packages("arules")
library(arules)

# Load the Groceries dataset
data("Groceries")

# Inspect the dataset
summary(Groceries)
inspect(head(Groceries, 5))  # View first 5 transactions

# Generate association rules
rules <- apriori(Groceries, 
                 parameter = list(supp = 0.01, conf = 0.5, target = "rules"))

# Inspect the rules
total_rules <- length(rules)
cat("Number of rules generated:", total_rules, "\n")

# Show top 10 rules sorted by lift
inspect(head(sort(rules, by = "lift"), 10))

# Visualize the rules (requires arulesViz package)
if (!require("arulesViz")) install.packages("arulesViz")
library(arulesViz)

plot(rules, method = "scatterplot", measure = c("support", "confidence"), shading = "lift")
plot(rules, method = "graph", control = list(type = "items"))

# Filter rules for specific insights
# Example: Rules where the item "whole milk" is in the right-hand side
milk_rules <- subset(rules, rhs %in% "whole milk")
inspect(head(sort(milk_rules, by = "lift"), 10))

# Save the rules to a CSV file
write(rules, file = "association_rules.csv", sep = ",", quote = TRUE, row.names = FALSE)

# ==============================
# Model Evaluation and Validation
# ==============================

# Evaluate quality of rules
rule_quality <- quality(rules)
cat("Summary of rule quality metrics:\n")
summary(rule_quality)

# Analyze rules with the highest support, confidence, and lift
cat("\nRules with highest support:\n")
inspect(head(sort(rules, by = "support"), 5))

cat("\nRules with highest confidence:\n")
inspect(head(sort(rules, by = "confidence"), 5))

cat("\nRules with highest lift:\n")
inspect(head(sort(rules, by = "lift"), 5))

# Validate rules: Filter rules with support > 0.02 and confidence > 0.6
validated_rules <- subset(rules, subset = support > 0.02 & confidence > 0.6)
cat("\nNumber of validated rules:", length(validated_rules), "\n")
inspect(head(sort(validated_rules, by = "lift"), 10))

# Validation for specific use case: Check if the rule set includes relationships with "yogurt"
yogurt_rules <- subset(validated_rules, lhs %in% "yogurt" | rhs %in% "yogurt")
cat("\nNumber of rules involving 'yogurt':", length(yogurt_rules), "\n")
inspect(head(sort(yogurt_rules, by = "confidence"), 5))



#Figure 8.8 Illustration of time series plot using synthetic data, where the first plot shows basic time series data with red points and blue lines. The second plot includes a smoothed trend line (green colour) to help visualize potential trends.
# Load necessary libraries
library(ggplot2)
library(tidyverse)
library(lubridate)

# Example: Loading Groceries dataset (replace with your actual data)
# For the sake of the example, let's simulate a dataset
set.seed(42)
date_range <- seq(as.Date("2020-01-01"), as.Date("2023-12-31"), by="days")
groceries_data <- data.frame(
  Date = date_range,
  Sales = abs(rnorm(length(date_range), mean = 50, sd = 10))  # Simulated sales data
)

# Ensure the Date column is of Date class
groceries_data$Date <- as.Date(groceries_data$Date)

# Aggregate data by month (you can adjust to weekly, yearly, etc.)
groceries_monthly <- groceries_data %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Month) %>%
  summarise(Total_Sales = sum(Sales))

# Plot the time series data with ggplot
ggplot(groceries_monthly, aes(x = Month, y = Total_Sales)) +
  geom_line(color = "blue") + 
  geom_point(color = "red") +
  labs(title = "Time Series Analysis of Groceries Sales", 
       x = "Month", 
       y = "Total Sales") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Optional: Add trend line for predictive analysis
ggplot(groceries_monthly, aes(x = Month, y = Total_Sales)) +
  geom_line(color = "blue") + 
  geom_point(color = "red") +
  geom_smooth(method = "loess", color = "green", se = FALSE) +  # Adding a trend line
  labs(title = "", 
       x = "Month", 
       y = "Total Sales") +
  theme_minimal(base_size = 20) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


#Figure 8.9 The forecasting groceries sales (next 12 months) using synthetic data.
# Load necessary libraries
library(ggplot2)
library(tidyverse)
library(lubridate)
library(forecast)  # For time series forecasting

# Example: Loading Groceries dataset (replace with your actual data)
# For the sake of the example, let's simulate a dataset
set.seed(42)
date_range <- seq(as.Date("2020-01-01"), as.Date("2023-12-31"), by="days")
groceries_data <- data.frame(
  Date = date_range,
  Sales = abs(rnorm(length(date_range), mean = 50, sd = 10))  # Simulated sales data
)

# Ensure the Date column is of Date class
groceries_data$Date <- as.Date(groceries_data$Date)

# Aggregate data by month (you can adjust to weekly, yearly, etc.)
groceries_monthly <- groceries_data %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Month) %>%
  summarise(Total_Sales = sum(Sales))

# Convert the data to a time series object
ts_data <- ts(groceries_monthly$Total_Sales, frequency = 12, start = c(2020, 1))  # Monthly data

# Fit ARIMA model for forecasting
arima_model <- auto.arima(ts_data)

# Forecast the next 12 months (adjust the forecast horizon as needed)
forecasted_values <- forecast(arima_model, h = 12)

# Plot the time series data and forecasted values
ggplot() +
  geom_line(data = groceries_monthly, aes(x = Month, y = Total_Sales), color = "blue") +
  geom_point(data = groceries_monthly, aes(x = Month, y = Total_Sales), color = "red") +
  geom_line(data = as.data.frame(forecasted_values), aes(x = seq(max(groceries_monthly$Month), 
                                                                 by = "month", length.out = 12), 
                                                         y = `Point Forecast`), color = "green", linetype = "dashed") +
  geom_ribbon(data = as.data.frame(forecasted_values), 
              aes(x = seq(max(groceries_monthly$Month), by = "month", length.out = 12), 
                  ymin = `Lo 80`, ymax = `Hi 80`), fill = "lightgreen", alpha = 0.5) +
  labs(title = "", 
       x = "Month", 
       y = "Total Sales") +
  theme_minimal(base_size = 20) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


#Figure 8.10 Bar plot of top 10 frequent sequential patterns 
# Load necessary libraries
library(arules)
library(arulesSequences)
library(tidyverse)
library(lubridate)

# Example: Simulating Groceries transactional data
set.seed(42)
customers <- paste0("C", sample(1:1000, 5000, replace = TRUE))  # Customer IDs
dates <- sample(seq(as.Date("2020-01-01"), as.Date("2023-12-31"), by = "day"), 5000, replace = TRUE)
products <- sample(c("Milk", "Bread", "Eggs", "Butter", "Cheese", "Apples", "Bananas", "Cereal", "Chicken", "Rice"), 5000, replace = TRUE)

# Create a transactional dataset
transactions <- data.frame(
  CustomerID = customers,
  Date = dates,
  Product = products
)

# Sort transactions by CustomerID and Date
transactions <- transactions %>%
  arrange(CustomerID, Date)

# Convert to transaction format for sequence mining
# Group transactions by CustomerID and Date
seq_data <- transactions %>%
  group_by(CustomerID, Date) %>%
  summarise(Products = paste(Product, collapse = ", ")) %>%
  ungroup()

# Save to a temporary file (required format for arulesSequences)
write.table(seq_data, file = "seq_data.csv", sep = ",", row.names = FALSE, col.names = FALSE, quote = FALSE)

# Read the data into a transaction object for sequence mining
seq_trans <- read_baskets("seq_data.csv", sep = ",", info = c("sequenceID", "eventID"))

# View the transaction summary
summary(seq_trans)

# Perform sequence mining using SPADE algorithm
seq_patterns <- cspade(seq_trans, parameter = list(support = 0.01))  # Adjust support threshold as needed

# Extract discovered patterns
patterns <- as(seq_patterns, "data.frame")
print(patterns)

# Visualize frequent patterns (top 10)
top_patterns <- patterns %>%
  arrange(desc(support)) %>%
  head(10)

ggplot(top_patterns, aes(x = reorder(sequence, support), y = support)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "", x = "Sequence", y = "Support") +
  theme_minimal(base_size = 20)
